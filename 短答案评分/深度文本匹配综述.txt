文本匹配
1 应用场景

信息检索， 智能客服，推荐，自动评分

2深度学习文本匹配

A基于单语义
B基于多语义
C直接建模匹配

A基于单语义：
核心问题：用一个向量表示一段文本。
B基于多语义：
分别提取词、短语、句子等不同级别的表达向量，再计算不同粒度向量间的相似度作为文本间的匹配度。

［２４，６３］中提出使用卷积神经网络来分别得到词、短语和句子等几个不同层面的文本表达，然后将这些向量拼接到一起或者建模这些向量之间的相似度来得到最终的匹配值．多粒度卷积神经网络（ＭｕｌｔｉＧｒａｎＣＮＮ）将１个句子拆解成４个层次，单词级别、短语级别、长短语级别和句子级别，之后将两个句子不同级别的特征进行两两的相似度计算，得到一个相似度矩阵， 进行动态最大值池化（３．３．１节）得到的就是两个句子的相似度得分。

双向循环神经网络得到的每个位置的表达也可
以类似看做一个变长的窗口［５４］的卷积操作，在不同
的位置可以有不同粒度的窗口，也就是说双向循环
神经网络可以生成多粒度的表达，这个和多粒度卷
积神经网络的功能是类似的，而且更加灵活的是窗
口的大小是一个软的边界，不像卷积核的大小是固
定的，并且可根据输入的数据不同灵活地变化

C挖掘文本交互后的模式特征，综合得到文本间的匹配度。

ＭａｔｃｈＰｙｒａｍｉｄ模型[26] 匹配矩阵

二维的循环神经网络［６６６８］

比较

基于单语义文档表达和多语义文档表达的深度模型都是将重点放在单个文本表达成一个向量，与
这些模型不同的是直接建模匹配模式的模型中并不
存在单个文本的表达，从模型的输入开始两段文本
就进行了交互，得到细粒度的匹配信息．也就是说在
单词级别的表达上直接来构造犕０的，之后基于这个
细粒度的匹配做更复杂的变换犵和犺．和基于单语
义文档表达的深度模型相比，这样的好处在于保持
细粒度的匹配信息，避免在一段文本抽象成一个表
达时，细节的匹配信息丢失．虽然多语义文档表达模
型在一定程度上缓解了这个问题，将不同粒度的表
达拼接成最终的表达，希望细粒度的匹配信息在
最后计算匹配得分的时候能够被考虑到，但是在得
到表达之后的计算还是偏向于简单的向量相似度计
算，缺少了直接建模匹配模式的挖掘，例如Ｍａｔｃｈ ＳＲＮＮ这种复杂的可以模拟最长公共子序列的匹
配模式

但是这类模型也有相应的缺点：（１）需要大量
的有监督的文本匹配的数据训练，没法通过无监督
的文本进行预训练；（２）预测的时候资源消耗较大， 每一对文档都得完全通过一遍网络，没法像基于单
语义文档表达或者多语义文档表达的模型可以离线
计算好每个文本的特征，预测的时候直接利用算好
的特征，并增量地计算新来的文本．因此这类模型一 般都是用于类似问答系统、翻译模型、对话系统这种
语义匹配程度高、句式变化复杂的任务中



















